{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Matching Algorithms\n",
    "\n",
    "![Medieval String Matching](https://github.com/ValRCS/RTU_Algorithms_DIP321/blob/main/imgs/Medieval_May%2020,%202025,%2011_13_48%20AM.png?raw=true)\n",
    "\n",
    "## Description\n",
    "\n",
    "### String Matching\n",
    "\n",
    "String matching is a fundamental problem in computer science. It is the process of finding a given pattern(needle) in a text(target or haystack). The pattern can be a string or a sequence of characters or a regular expression.\n",
    "\n",
    "Haystack might not be the best description since string is a sequence of characters and not a stack. But it is a common term used in string matching algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 23, 38, 38)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in python we already have string find / index method\n",
    "text = \"MIT HARVARD OXFORD RRRRRTU RTU RTUUUU RTU ???\"\n",
    "text.find(\"RTU\"), text.index(\"RTU\"), text.rfind(\"RTU\"), text.rindex(\"RTU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23, 27, 31, 38]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how about finding all indexes of a substring that matches the search string\n",
    "# we can loop through the string and find the index of the substring and then move the pointer to the next index\n",
    "needle = \"RTU\"\n",
    "text = \"MIT HARVARD OXFORD RRRRRTU RTU RTUUUU RTU ???\"\n",
    "# we will save indexes in a list - so we start with a blank container\n",
    "indexes = []\n",
    "# we will start from 0\n",
    "index = 0\n",
    "# we will loop through the text\n",
    "while index < len(text):\n",
    "    # we will find the index of the substring\n",
    "    index = text.find(needle, index) # so find has a start index\n",
    "    # if we find it we will add it to the list\n",
    "    if index != -1:\n",
    "        indexes.append(index)\n",
    "        # we will move the pointer to the next index - this way we do not find the same substring again, we start looking from the next index\n",
    "        index += 1\n",
    "    else: # means we did not find the substring\n",
    "        break\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at index 23 RTU\n",
      "Starting at index 27 RTU\n",
      "Starting at index 31 RTU\n",
      "Starting at index 38 RTU\n"
     ]
    }
   ],
   "source": [
    "# we can double check using slicing and lenght of the needle\n",
    "for index in indexes:\n",
    "    print(f\"Starting at index {index}\", text[index:index+len(needle)]) # so we slice the text from the index to the index + length of the needle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute force approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_needle(text, needle):\n",
    "    '''\n",
    "    Brute force search for needle in text\n",
    "    '''\n",
    "    for i in range(len(text)): # more Pythonic would be to use enumerate\n",
    "        # python slicing makes this easy\n",
    "        # we check whether current window of text matches the needle\n",
    "        if text[i:i+len(needle)] == needle: \n",
    "            return i # if we had to find all we could add the index to a list\n",
    "    return -1\n",
    "\n",
    "find_needle(text, \"RTU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets rewrite the above function without slicing\n",
    "def find_needle_no_slice(text, needle):\n",
    "    '''\n",
    "    Brute force search for needle in text\n",
    "    Not pythonic implementation - more like C\n",
    "    '''\n",
    "    for i in range(len(text)-len(needle)+1): # slight optimization we do not need to go to the end of the text\n",
    "        # python slicing makes this easy\n",
    "        for j in range(len(needle)):\n",
    "            if text[i+j] != needle[j]: # so we check each character one by one\n",
    "                # here we would add a flag if we did not use the else for the for loop (not available in C or Java)\n",
    "                break # we failed to find the needle so no need to continue inner loop\n",
    "        else: # this else is for the for loop, not the if - it means we did not break out of the loop\n",
    "            return i # if we didn't break out of the loop, we found the needle\n",
    "\n",
    "    return -1\n",
    "\n",
    "find_needle_no_slice(text, \"RTU\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity of brute force algorithm\n",
    "\n",
    "The brute force algorithm is the simplest algorithm for string matching. It checks for the pattern in the text by sliding the pattern over the text one by one and checking for a match. The time complexity of this algorithm is O(mn) where m is the length of the pattern and n is the length of the text(**needle** stands for n).\n",
    "\n",
    "Sometimes the m an n are used to represent the length of the pattern and text respectively. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knuth-Morris-Pratt Algorithm\n",
    "\n",
    "### Description\n",
    "\n",
    "**Big idea: If we know some of the characters in the text, we can use that information to avoid matching the characters that we know will anyway match.**\n",
    "\n",
    "![Steam Punk]()\n",
    "\n",
    "In KMP we build a prefix table that tells us how many characters to skip when a mismatch occurs. This is called the failure function or the prefix function.\n",
    "We could use this information to skip characters in the text that we know will anyway match.\n",
    "\n",
    "We could also build a DFA using this information.\n",
    "\n",
    "DFA - Deterministic Finite Automaton\n",
    "https://en.wikipedia.org/wiki/Deterministic_finite_automaton\n",
    "\n",
    "### Complexity\n",
    "\n",
    "Time complexity: O(m+n) where m is the length of the pattern and n is the length of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kmp_table(needle):\n",
    "    '''\n",
    "    Build the KMP table for the needle\n",
    "    '''\n",
    "    # initialize table\n",
    "    table = [0]*len(needle)\n",
    "    i = 1\n",
    "    j = 0\n",
    "    # we start at 1 because table[0] is always 0\n",
    "    while i < len(needle): \n",
    "        if needle[i] == needle[j]:\n",
    "            table[i] = j+1\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif j > 0:\n",
    "            j = table[j-1]\n",
    "        else:\n",
    "            i += 1\n",
    "    return table\n",
    "\n",
    "kmp_table(\"RTU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links on building DFA\n",
    "\n",
    "* Original paper by Knuth-Morris-Pratt: TODO\n",
    "* Video: - https://www.youtube.com/watch?v=GTJr8OvyEVQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 2, 2]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmp_table(\"aabaaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kmp search\n",
    "def kmp_search(text, needle, table=None):\n",
    "    '''\n",
    "    KMP search for needle in text\n",
    "    '''\n",
    "    if table is None:\n",
    "        table = kmp_table(needle) # so if we had a table we would use it - building table has complexity O(n) - where n is the length of the needle\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < len(text):\n",
    "        if text[i] == needle[j]:\n",
    "            # so if we are at the end of the needle, we found it!!\n",
    "            if j == len(needle)-1:\n",
    "                return i-j\n",
    "            else:\n",
    "                i += 1\n",
    "                j += 1\n",
    "        elif j > 0:\n",
    "            j = table[j-1] # essentially it is the same DFA as in the table - so we know how many characters we can skip\n",
    "        else:\n",
    "            i += 1\n",
    "    return -1\n",
    "\n",
    "kmp_search(text, \"RTU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left as an exercise for the reader run timing tests on the above functions\n",
    "# and compare them to the python find method\n",
    "\n",
    "# you can use %timeit in a jupyter notebook to time a function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boyer-Moore Algorithm\n",
    "\n",
    "https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string-search_algorithm\n",
    "\n",
    "![1980s](https://github.com/ValRCS/RTU_Algorithms_DIP321/blob/main/imgs/1980s_May%2020,%202025,%2011_07_58%20AM.png?raw=true)\n",
    "\n",
    "### Description\n",
    "\n",
    "Boyer-Moore algorithm is a string searching algorithm that uses information from the end of the pattern to skip characters in the text. It uses two rules to skip characters in the text.\n",
    "\n",
    "1. Bad character rule\n",
    "Bad character rule is used to skip characters in the text when a mismatch occurs. The bad character rule is based on the observation that if the mismatch occurs at position i in the pattern, then we can shift the pattern by i characters to the right.\n",
    "2. Good suffix rule\n",
    "TODO good suffix rule\n",
    "\n",
    "### Example page\n",
    "\n",
    "Author: Robert C. Moore\n",
    "https://www.cs.utexas.edu/users/moore/best-ideas/string-searching/fstrpos-example.html\n",
    "\n",
    "\n",
    "\n",
    "### Complexity\n",
    "\n",
    "Worst case time complexity: O(mn) where m is the length of the pattern and n is the length of the text.\n",
    "\n",
    "Best case time complexity: O(n/m) where m is the length of the pattern/needle and n is the length of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's implement Boyer Moore\n",
    "def boyer_moore(text, needle):\n",
    "    '''\n",
    "    Boyer Moore search for needle in text\n",
    "    '''\n",
    "    # build bad character table\n",
    "    table = {}\n",
    "    for i in range(len(needle)):\n",
    "        table[needle[i]] = i\n",
    "    # now we search\n",
    "    i = len(needle)-1 # start at the end of the needle!\n",
    "    j = i\n",
    "    while i < len(text):\n",
    "        if text[i] == needle[j]:\n",
    "            if j == 0:\n",
    "                return i\n",
    "            else:\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "        else:\n",
    "            if text[i] in table:\n",
    "                i += len(needle) - min(j, 1+table[text[i]])\n",
    "            else:\n",
    "                i += len(needle)\n",
    "            j = len(needle)-1\n",
    "    return -1\n",
    "\n",
    "boyer_moore(text, \"RTU\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAGCCCAATA'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "# insert seed here\n",
    "random.seed(42) # answer to life the universe and everything\n",
    "long_random_text = \"\".join([random.choice(\"ACGT\") for i in range(1_000_000)])\n",
    "long_random_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27459"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movie GATTACA - url https://www.imdb.com/title/tt0119177/\n",
    "needle = \"GATTACA\"\n",
    "long_random_text.find(needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.2 µs ± 2.02 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit long_random_text.find(needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.63 ms ± 165 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit find_needle(long_random_text, needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.24 ms ± 479 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit find_needle_no_slice(long_random_text, needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.34 ms ± 431 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit boyer_moore(long_random_text, needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.06 ms ± 233 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit kmp_search(long_random_text, needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CGTGGTTGGTTTCGGATCTGTTGACAGAGAACTGACCCCATCCGCCTTGA'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let'' look at the end of the long_random_text\n",
    "long_random_text[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our needle will be last 100 characters\n",
    "needle = long_random_text[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23 ms ± 17.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "long_random_text.find(needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 ms ± 4.54 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "find_needle(long_random_text, needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267 ms ± 11.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "find_needle_no_slice(long_random_text, needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 ms ± 7.89 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "kmp_search(long_random_text, needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 ms ± 9.97 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "boyer_moore(long_random_text, needle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python implemention of find\n",
    "\n",
    "Turns out that the python find method is implemented using the Boyer-Moore algorithm. Actually a modified version of Boyer-Moore algorithm called the Boyer-Moore-Horspool algorithm.\n",
    "\n",
    "* https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore%E2%80%93Horspool_algorithm\n",
    "* Stack Overflow: https://stackoverflow.com/questions/681649/how-is-string-find-implemented-in-cpython"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing longer needles\n",
    "\n",
    "We expect that Boyer Moore and KMP will be faster than brute force for longer needles. Let's test this hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GCCATATTACTTAGGTTAAGGTTGGCGTACTCGTGTTTAACATCCGGCCTACGCAGGCTATTTTATACATTATTGTACTTTTTGATAGTTAGTCAATGCGCCACCGGTTCGTTAGAGGGTAGGTATCTCTTTTGGCGAGGATGCACGTCC'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets get some longer needle from back of the long_random_text\n",
    "needle = long_random_text[-200:-50]\n",
    "needle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6 ms ± 72.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit long_random_text.find(needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303 ms ± 27.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit find_needle(long_random_text, needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378 ms ± 42.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit boyer_moore(long_random_text, needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261 ms ± 24.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit kmp_search(long_random_text, needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's replace some characters in the long random text with X\n",
    "long_list = list(long_random_text)\n",
    "for i in range(950):\n",
    "    long_list[i*1000] = \"X\"\n",
    "long_random_text = \"\".join(long_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233 ms ± 7.17 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit boyer_moore(long_random_text, needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 ms ± 3.54 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit find_needle(long_random_text, needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.61 ms ± 171 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit long_random_text.find(needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so it does look like find and our naive Boyer Moore improve when text contains characters that are NOT in the needle\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing longer needles with longer text\n",
    "\n",
    "Finally we will use bigger alphabets and longer texts to see how the algorithms perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "letters = string.ascii_letters\n",
    "letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zyjnFPQbKJRTsQEawcXZWYnKTlJiZCbduFFXofSHHwcdGoTMpYsCcQMBpaYdcoNPXWnJChYWGcfsAGMKIVKwuLnEpWBSPOKeQdvfQuYGbYbRghMOsuQrzezdMwXnpePcIbpMzdahLYAHkwFXLYFGDj'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_text = \"\".join([random.choice(letters) for i in range(1000000)])\n",
    "needle = long_text[-200:-50]\n",
    "needle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(needle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999800"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_text.find(needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336 µs ± 46.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit long_text.find(needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269 ms ± 30.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit find_needle(long_text, needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284 ms ± 26.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit kmp_search(long_text, needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 ms ± 681 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit boyer_moore(long_text, needle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rabin-Karp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Rabin-Karp algorithm** is a clever string searching technique that uses **hashing** to find all occurrences of a pattern in a text. It is particularly efficient when you need to search for **multiple patterns** in the same text.\n",
    "\n",
    "---\n",
    "\n",
    "## 📜 History\n",
    "\n",
    "The Rabin-Karp algorithm was developed by **Michael O. Rabin and Richard M. Karp** in **1987**. It introduced a **probabilistic hashing approach** to string matching, making it faster in many real-world scenarios, especially for **multi-pattern searching**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Key Idea\n",
    "\n",
    "Instead of checking characters one by one (like KMP or Boyer-Moore), Rabin-Karp:\n",
    "\n",
    "1. Computes a **hash** of the pattern.\n",
    "2. Computes hashes of all substrings of the text with the same length.\n",
    "3. Compares hashes:\n",
    "\n",
    "   * If hash matches, do a **character-by-character check** to confirm.\n",
    "   * If not, move on.\n",
    "\n",
    "> This is called a **rolling hash** because we efficiently update the hash as we slide the window.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔢 Hash Function (Basic Version)\n",
    "\n",
    "Use a polynomial hash:\n",
    "\n",
    "```\n",
    "hash(s) = s[0]*base^(m-1) + s[1]*base^(m-2) + ... + s[m-1]*base^0 mod q\n",
    "```\n",
    "\n",
    "* `base` is a constant (like 256 for ASCII)\n",
    "* `q` is a prime number to avoid large numbers and reduce collisions\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Python Implementation\n",
    "\n",
    "```python\n",
    "def rabin_karp(text, pattern, base=256, q=101):\n",
    "    \"\"\"\n",
    "    Rabin-Karp string matching using rolling hash.\n",
    "    - base: size of character set (e.g., 256 for extended ASCII)\n",
    "    - q: a prime number to mod the hash values\n",
    "    Returns list of starting indices where pattern is found in text.\n",
    "    \"\"\"\n",
    "    n = len(text)\n",
    "    m = len(pattern)\n",
    "\n",
    "    if m > n:\n",
    "        return []\n",
    "\n",
    "    pattern_hash = 0  # hash value for pattern\n",
    "    text_hash = 0     # hash value for current text window\n",
    "    h = 1             # high-order base multiplier (base^(m-1) % q)\n",
    "\n",
    "    # Precompute h = pow(base, m-1) % q\n",
    "    for _ in range(m - 1):\n",
    "        h = (h * base) % q\n",
    "\n",
    "    # Compute the hash value for pattern and first window of text\n",
    "    for i in range(m):\n",
    "        pattern_hash = (base * pattern_hash + ord(pattern[i])) % q\n",
    "        text_hash = (base * text_hash + ord(text[i])) % q\n",
    "\n",
    "    matches = []\n",
    "\n",
    "    # Slide the pattern over text one by one\n",
    "    for i in range(n - m + 1):\n",
    "        # Check if the hash values match\n",
    "        if pattern_hash == text_hash:\n",
    "            # Double-check with direct character comparison\n",
    "            if text[i:i + m] == pattern:\n",
    "                matches.append(i)\n",
    "\n",
    "        # Compute the hash of the next window\n",
    "        if i < n - m:\n",
    "            text_hash = (base * (text_hash - ord(text[i]) * h) + ord(text[i + m])) % q\n",
    "            # Make sure hash is positive\n",
    "            if text_hash < 0:\n",
    "                text_hash += q\n",
    "\n",
    "    return matches\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Example Usage\n",
    "\n",
    "```python\n",
    "text = \"the quick brown fox jumps over the lazy dog\"\n",
    "pattern = \"over\"\n",
    "print(\"Pattern found at indices:\", rabin_karp(text, pattern))\n",
    "```\n",
    "\n",
    "### Output:\n",
    "\n",
    "```\n",
    "Pattern found at indices: [26]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ⏱️ Time Complexity\n",
    "\n",
    "| Case         | Complexity |\n",
    "| ------------ | ---------- |\n",
    "| Average Case | O(n + m)   |\n",
    "| Worst Case   | O(n \\* m)  |\n",
    "\n",
    "* `n`: length of text\n",
    "* `m`: length of pattern\n",
    "* Worst-case happens when there are many hash collisions.\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 Advantages & Use Cases\n",
    "\n",
    "* **Efficient for multiple pattern matching** (just hash each pattern and compare).\n",
    "* Used in **plagiarism detection**, **virus signature scanning**, **dictionary matching**.\n",
    "* Simple to adapt for **binary data**, **DNA**, and other non-textual sequences.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ Notes on Practical Use\n",
    "\n",
    "* Choice of `q` (modulus) and `base` affects performance and collision rate.\n",
    "* Real implementations may use **Rabin fingerprints**, **rolling hashes with primes**, or **double hashing** for reliability.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needle: RTU\n",
      "Text: MIT HARVARD OXFORD RRRRRTU RTU RTUUUU RTU ???\n",
      "Text length: 45\n",
      "Needle length: 3\n",
      "Needle found at: [23, 27, 31, 38]\n"
     ]
    }
   ],
   "source": [
    "def rabin_karp(text, pattern, base=256, q=101):\n",
    "    \"\"\"\n",
    "    Rabin-Karp string matching using rolling hash.\n",
    "    - base: size of character set (e.g., 256 for extended ASCII)\n",
    "    - q: a prime number to mod the hash values\n",
    "    Returns list of starting indices where pattern is found in text.\n",
    "    \"\"\"\n",
    "    n = len(text)\n",
    "    m = len(pattern)\n",
    "\n",
    "    if m > n:\n",
    "        return []\n",
    "\n",
    "    pattern_hash = 0  # hash value for pattern\n",
    "    text_hash = 0     # hash value for current text window\n",
    "    h = 1             # high-order base multiplier (base^(m-1) % q)\n",
    "\n",
    "    # Precompute h = pow(base, m-1) % q\n",
    "    for _ in range(m - 1):\n",
    "        h = (h * base) % q\n",
    "\n",
    "    # Compute the hash value for pattern and first window of text\n",
    "    for i in range(m):\n",
    "        pattern_hash = (base * pattern_hash + ord(pattern[i])) % q\n",
    "        text_hash = (base * text_hash + ord(text[i])) % q\n",
    "\n",
    "    matches = []\n",
    "\n",
    "    # Slide the pattern over text one by one\n",
    "    for i in range(n - m + 1):\n",
    "        # Check if the hash values match\n",
    "        if pattern_hash == text_hash:\n",
    "            # Double-check with direct character comparison\n",
    "            if text[i:i + m] == pattern:\n",
    "                matches.append(i)\n",
    "\n",
    "        # Compute the hash of the next window\n",
    "        if i < n - m:\n",
    "            text_hash = (base * (text_hash - ord(text[i]) * h) + ord(text[i + m])) % q\n",
    "            # Make sure hash is positive\n",
    "            if text_hash < 0:\n",
    "                text_hash += q\n",
    "\n",
    "    return matches\n",
    "\n",
    "# our needle\n",
    "needle = \"RTU\"\n",
    "print(f\"Needle: {needle}\")\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Text length: {len(text)}\")\n",
    "print(f\"Needle length: {len(needle)}\")\n",
    "print(f\"Needle found at: {rabin_karp(text, needle)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Boyer-Moore performs best when there are many potential \"easy losses\" - some character is present in the text but not in the pattern. \n",
    "\n",
    "KMP will be faster than brute force when the pattern has many repeated characters.\n",
    "\n",
    "Use Rabin-Karp when you need to search for multiple patterns in the same text. It is also useful when you need to search for a pattern in a large text with many repeated characters.\n",
    "The Rabin-Karp algorithm is particularly efficient when you need to search for multiple patterns in the same text. It is also useful when you need to search for a pattern in a large text with many repeated characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources for String Matching Algorithms\n",
    "\n",
    "While the teacher has checked the links, it is possible that some links break in the future. If you find a broken link, please let me know and I will fix it.\n",
    "E-mail: valdis.saulespurens@rtu.lv\n",
    "\n",
    "Second note, there are some authorative links such as academic papers but also some less formal links such as blog posts and articles. I have tried to mark the links with the type of resource they are.\n",
    "\n",
    "\n",
    "\n",
    "| Algorithm       | Resource Name & Link                                                  | URL                                                         | Type                     | Description                                                                                         | Date           |\n",
    "|----------------|------------------------------------------------------------------------|--------------------------------------------------------------|--------------------------|-----------------------------------------------------------------------------------------------------|----------------|\n",
    "| Naïve          | [GeeksforGeeks: Naive Pattern Searching](https://www.geeksforgeeks.org/naive-algorithm-for-pattern-searching/) | https://www.geeksforgeeks.org/naive-algorithm-for-pattern-searching/ | Tutorial (article)       | Basic brute-force matching explained with code and examples.                                        | Apr 20, 2024   |\n",
    "| Naïve          | [Exact String Matching Algorithms: Brute Force](https://www-igm.univ-mlv.fr/~lecroq/string/node3.html)         | https://www-igm.univ-mlv.fr/~lecroq/string/node3.html         | Academic resource        | Charras & Lecroq's comprehensive 1997 writeup with C code and algorithm description.                | Jan 14, 1997   |\n",
    "| KMP            | [Dev.to: Understanding the KMP Algorithm](https://dev.to/yo-shi/for-beginners-understanding-the-kmp-algorithm-by-comparing-with-the-brute-force-1da3)           | https://dev.to/yo-shi/for-beginners-understanding-the-kmp-algorithm-by-comparing-with-the-brute-force-1da3     | Blog post                | Simple explanation of KMP with examples and comparisons to brute force.                             | Jan 4, 2025    |\n",
    "| KMP            | [Virtual Labs: KMP Algorithm](https://ds2-iiith.vlabs.ac.in/exp/kmp-algorithm/index.html)                            | https://ds2-iiith.vlabs.ac.in/exp/kmp-algorithm/index.html          | Interactive tutorial     | Animation and quiz for learning KMP through simulations.                                            | —              |\n",
    "| KMP            | [Knuth, Morris, Pratt (1977)](https://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Knuth77.pdf)                                   | https://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Knuth77.pdf                  | Academic paper           | The original paper introducing KMP, with formal proofs and linear time analysis.                    | 1977           |\n",
    "| Boyer-Moore    | [Medium: Boyer-Moore String Search](https://medium.com/@siddharth.21/the-boyer-moore-string-search-algorithm-674906cab162)  | https://medium.com/@siddharth.21/the-boyer-moore-string-search-algorithm-674906cab162 | Blog post      | Explanation of both bad-character and good-suffix rules with Python code.                          | Oct 19, 2021   |\n",
    "| Boyer-Moore    | [UBC Visualization: Boyer-Moore Search](https://cmps-people.ok.ubc.ca/ylucet/DS/BoyerMoore.html)                  | https://cmps-people.ok.ubc.ca/ylucet/DS/BoyerMoore.html            | Interactive tool         | Step-by-step animation of Boyer-Moore alignment and pattern shifts.                                | —              |\n",
    "| Boyer-Moore    | [Boyer & Moore (1977)](https://www.cs.utexas.edu/~moore/publications/fstrpos.pdf)                                         | https://www.cs.utexas.edu/~moore/publications/fstrpos.pdf                  | Academic paper           | Foundational work that introduced Boyer-Moore and sublinear average-case search.                   | 1977           |\n",
    "| Rabin-Karp     | [GeeksforGeeks: Rabin-Karp Algorithm](https://www.geeksforgeeks.org/rabin-karp-algorithm-for-pattern-searching/) | https://www.geeksforgeeks.org/rabin-karp-algorithm-for-pattern-searching/ | Tutorial (article) | Clear step-by-step example of Rabin-Karp’s rolling hash technique.                                 | Feb 26, 2025   |\n",
    "| Rabin-Karp     | *Introduction to Algorithms* (Cormen et al.)                           | https://mitpress.mit.edu/9780262046305/                      | Textbook (paid)          | Covers Rabin-Karp and compares it with other algorithms in detail.                                 | 2022           |\n",
    "| Rabin-Karp     | [Karp & Rabin (1987)](https://citeseerx.ist.psu.edu/document?doi=c47d151f09c567013761632c89e237431c6291a2)                                              | https://citeseerx.ist.psu.edu/document?doi=c47d151f09c567013761632c89e237431c6291a2                    | Academic paper           | The original randomized pattern-matching paper for multiple patterns.                               | 1987           |\n",
    "| Aho-Corasick   | [Aho & Corasick (1975)](https://cr.yp.to/bib/1975/aho.pdf)                                         | https://cr.yp.to/bib/1975/aho.pdf                  | Academic paper           | Introduced the multi-pattern matching algorithm using tries and failure transitions.                | 1975           |\n",
    "| Suffix Trees   | [Ukkonen (1995)](https://link.springer.com/article/10.1007/BF01206331)                                         | https://link.springer.com/article/10.1007/BF01206331          | Academic paper           | Describes the first linear-time online suffix tree construction algorithm.                          | 1995           |\n",
    "| Levenshtein    | [Levenshtein (1966)](https://nymity.ch/sybilhunting/pdf/Levenshtein1966a.pdf) | https://nymity.ch/sybilhunting/pdf/Levenshtein1966a.pdf | Academic paper | Defines the edit distance and lays the foundation for approximate matching and corrections.         | 1966           |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
